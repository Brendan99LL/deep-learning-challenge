<h1>Neural Network Model Report</h1>

<h3>Optimization Attempts Summaries:</h3>
<ol>
  <li>Optimization Attempt # 1</li>
    <ul>
      <li>Activation Functions: Relu, Sigmoid, Relu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 10, 9, 8, 1</li>
      <li>Epochs = 100</li>
      <li>Accuracy: 73.03%</li>
    </ul>
  <li>Optimization Attempt # 2</li>
    <ul>
      <li>Activation Functions: Relu, Sigmoid, Elu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 20, 19, 18, 1</li>
      <li>Epochs = 100</li>
      <li>Accuracy: 72.93%</li>
    </ul>
  <li>Optimization Attempt # 3</li>
    <ul>
      <li>Activation Functions: Relu, Relu, Relu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 80, 50, 25, 1</li>
      <li>Epochs = 100</li>
      <li>Accuracy: 73.20%</li>
    </ul>
  <li>Optimization Attempt # 4</li>
    <ul>
      <li>Activation Functions: Relu, Relu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 10, 8, 1</li>
      <li>Epochs = 100</li>
      <li>Accuracy: 72.58%</li>
    </ul>
  <li>Optimization Attempt # 5</li>
    <ul>
      <li>Activation Functions: Relu, Sigmoid, Sigmoid (output)</li>
      <li>Hidden Layer Units: 16, 16, 1</li>
      <li>Epochs = 50</li>
      <li>Accuracy: 72.79%</li>
    </ul>
  <li>Optimization Attempt # 6</li>
    <ul>
      <li>Activation Functions: Relu, Relu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 16, 16, 1</li>
      <li>Epochs = 50</li>
      <li>Accuracy: 72.47%</li>
    </ul>
  <li>Optimization Attempt # 7</li>
    <ul>
      <li>Activation Functions: Relu, Elu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 16, 16, 1</li>
      <li>Epochs = 50</li>
      <li>Accuracy: 72.93%</li>
    </ul>
  <li>Optimization Attempt # 8</li>
    <ul>
      <li>Activation Functions: Relu, Relu, Elu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 16, 16, 16, 1</li>
      <li>Epochs = 50</li>
      <li>Accuracy: 72.93%</li>
    </ul>
  <li>Optimization Attempt # 9</li>
    <ul>
      <li>Activation Functions: Relu, Relu, Relu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 16, 16, 16, 1</li>
      <li>Epochs = 50</li>
      <li>Accuracy: 73.16%</li>
    </ul>
  <li>Optimization Attempt # 10</li>
    <ul>
      <li>Activation Functions: Relu, Sigmoid, Elu, Sigmoid (output)</li>
      <li>Hidden Layer Units: 16, 16, 16, 1</li>
      <li>Epochs = 50</li>
      <li>Accuracy: 73.04%</li>
    </ul>  
</ol>
